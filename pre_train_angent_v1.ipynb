{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4d0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.config import Config\n",
    "from src.episode import Episode\n",
    "from src.episode_dataset import EpisodeSupervisedDataset\n",
    "from src.rl_data_record import RLDataRecord\n",
    "from src.policy_factory import PolicyMode, PolicyFactory\n",
    "from src.reward_model import RewardModel\n",
    "from src.pre_trainer import PreTrainer\n",
    "from src.policy_model_utils import load_policy_model, save_policy_model, train_and_plot_policy, inference_and_plot_pre_train_policy, inference_and_plot_policy_v2\n",
    "from src.utils import get_color, normalize_min_max, to_device_collate, top_k_sampling\n",
    "from src.episode_batch_repeat_sampler import EpisodeBatchRepeatSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95d5dac",
   "metadata": {},
   "source": [
    "# Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30afabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "reward_model = RewardModel(config=config)\n",
    "test_policy = PolicyFactory.create(\n",
    "    policy_mode=PolicyMode.TRANSFORMER_WITH_LATE_POSITION_FUSION, config=config\n",
    ")\n",
    "\n",
    "# Datasets\n",
    "\n",
    "train_dataset = EpisodeSupervisedDataset(config=config, split=\"TRAIN\")\n",
    "print(f\"train_dataset : {len(train_dataset)}\")\n",
    "\n",
    "test_dataset = EpisodeSupervisedDataset(config=config, split=\"TEST\")\n",
    "print(f\"test_dataset : {len(test_dataset)}\")\n",
    "\n",
    "eval_dataset = EpisodeSupervisedDataset(config=config, split=\"EVAL\")\n",
    "print(f\"eval_dataset : {len(eval_dataset)}\")\n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "def get_data_loader(\n",
    "    dataset: EpisodeSupervisedDataset, batch_size: int, shuffle: bool = True\n",
    "):\n",
    "    to_device_collate_configurable = partial(to_device_collate, config.device)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=to_device_collate_configurable,\n",
    "    )\n",
    "    print(f\"data loader: {dataset.split}, {len(dataloader)}\")\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "train_dataloader = get_data_loader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config.train_batch_size,\n",
    ")\n",
    "\n",
    "test_dataloader = get_data_loader(\n",
    "    dataset=test_dataset, batch_size=config.test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "eval_dataloader = get_data_loader(\n",
    "    dataset=eval_dataset,\n",
    "    batch_size=config.eval_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_samples = 4\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=episode_samples, ncols=3, squeeze=False, figsize=(15, 20)\n",
    ")\n",
    "\n",
    "cur_eidx = 0\n",
    "for eidx in range(episode_samples):\n",
    "    es = train_dataset.get_episode(cur_eidx)\n",
    "    cur_eidx += len(es.best_path)\n",
    "    es.viz(ax=axes[eidx][0], reward_model=reward_model)\n",
    "\n",
    "    # Viz fov\n",
    "    fov = es.fov(center_pos=es.agent.start_state.position())\n",
    "    # print(f\"fov: {fov.size()}, {fov}\")\n",
    "    # print(f\"fov: {fov}\")\n",
    "    es.viz_fov(ax=axes[eidx][1])\n",
    "    es.viz_optimal_path(ax=axes[eidx][2])\n",
    "\n",
    "    es = train_dataset.get_episode(eidx)\n",
    "    # print(f\"best_path: {es.best_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3306c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba454e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcb1f495",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d1f5972",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = PolicyFactory.create(\n",
    "    policy_mode=PolicyMode.TRANSFORMER_WITH_LATE_POSITION_FUSION, config=config\n",
    ").to(config.device)\n",
    "pre_trainer = PreTrainer(config=config, policy=policy)\n",
    "pre_trainer.run(train_dataset=train_dataset, eval_dataset=eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea392d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = PolicyFactory.create(\n",
    "#     policy_mode=PolicyMode.TRANSFORMER_WITH_LATE_POSITION_FUSION, config=config\n",
    "# ).to(config.device)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(policy.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "# # Instantiate the CrossEntropyLoss\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# total_steps = config.epoches * len(train_dataloader)\n",
    "# warmup_steps = 0\n",
    "# # Cosine annealing scheduler\n",
    "# learning_rate_scheduler = CosineAnnealingLR(optimizer, T_max=total_steps - warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tqdm(total=len(train_dataloader) * config.epoches) as pbar:\n",
    "#     for _ in range(config.epoches):\n",
    "#         for batch_data in train_dataloader:\n",
    "#             batch_fov: torch.Tensor = batch_data[\"fov\"]\n",
    "#             batch_cur_position: torch.Tensor = batch_data[\"agent_current_pos\"]\n",
    "#             batch_target_position: torch.Tensor = batch_data[\"agent_target_pos\"]\n",
    "#             batch_best_next_pos: torch.Tensor = batch_data[\"best_next_pos\"]\n",
    "#             batch_best_next_action: torch.Tensor = batch_data[\"best_next_action\"]\n",
    "#             batch_logits = policy(\n",
    "#                 batch_fov=batch_fov,\n",
    "#                 batch_cur_position=batch_cur_position,\n",
    "#                 batch_target_position=batch_target_position,\n",
    "#             )\n",
    "#             batch_probability = F.softmax(batch_logits, dim=1)\n",
    "#             # print(f\"batch_logits: {batch_logits.shape}\")\n",
    "#             # print(f\"batch_probability: {batch_probability.shape}\")\n",
    "\n",
    "#             loss = criterion(batch_logits, batch_best_next_action)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             learning_rate_scheduler.step()\n",
    "#             current_lr = learning_rate_scheduler.get_last_lr()[0]\n",
    "\n",
    "#             pbar.set_description(f\"Loss: {loss}, Lr: {current_lr}\")\n",
    "#             pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d84c5",
   "metadata": {},
   "source": [
    "# Eval Policy\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab030195",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model = RewardModel(config=config)\n",
    "\n",
    "inference_and_plot_pre_train_policy(\n",
    "    config=config,\n",
    "    dataset=test_dataset,\n",
    "    dataloader=test_dataloader,\n",
    "    policy=policy,\n",
    "    steps=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03266593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
