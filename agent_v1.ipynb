{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80345412",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.action import Action\n",
    "from src.agent import Agent\n",
    "from src.config import Config\n",
    "from src.episode import Episode\n",
    "from src.policy.policy_base import PolicyBaseModel\n",
    "from src.policy_factory import PolicyMode, PolicyFactory\n",
    "from src.reward_model import RewardModel\n",
    "from src.state import State\n",
    "from src.utils import top_k_sampling\n",
    "from src.world import World\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b28aa3",
   "metadata": {},
   "source": [
    "# Random agent action history\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6660c631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config()\n",
    "reward_model = RewardModel(config=config)\n",
    "world_board = np.zeros(shape=(config.world_height, config.world_width))\n",
    "world_board.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cd6731",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = Episode.new(episode_id=\"test\")\n",
    "episode.run_steps_by_random(steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd94e4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Episode.viz() missing 1 required positional argument: 'reward_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mfigure_size)\n\u001b[1;32m      2\u001b[0m ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m episode\u001b[38;5;241m.\u001b[39mviz(ax\u001b[38;5;241m=\u001b[39max)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mTypeError\u001b[0m: Episode.viz() missing 1 required positional argument: 'reward_model'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=config.figure_size)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "episode.viz(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a65288",
   "metadata": {},
   "source": [
    "# Policy Guide agent action history\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = Episode.new(id=\"test\")\n",
    "policy = PolicyFactory.create(\n",
    "    policy_mode=PolicyMode.LINEAR_MODEL, config=episode.config\n",
    ").to(episode.config.device)\n",
    "\n",
    "episode.run_steps_by_policy(\n",
    "    steps=20, policy=policy, top_k=episode.config.top_k, debug=True\n",
    ")\n",
    "print(f\"episode reward: {episode.reward(reward_model=reward_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=config.figure_size)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "episode.viz(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794436c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85fad34f",
   "metadata": {},
   "source": [
    "# TRAIN Policy\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597595ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(idx: int):\n",
    "    colors = [\"red\", \"green\", \"blue\", \"gray\"]\n",
    "    return colors[idx % len(colors)]\n",
    "\n",
    "\n",
    "def train_and_plot_policy(policy: PolicyBaseModel, debug: bool = False):\n",
    "    episode = Episode.new(id=\"train\")\n",
    "    print(f\"start: {episode.agent.current_state}\")\n",
    "    episode.train(steps=20, policy=policy, debug=debug)\n",
    "    print(f\"start2: {episode.agent.current_state}\")\n",
    "\n",
    "    fig = plt.figure(figsize=config.figure_size)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    episode.viz(ax=ax, color=get_color(0))\n",
    "    plt.show()\n",
    "\n",
    "    return episode\n",
    "\n",
    "\n",
    "def inference_and_plot_policy(\n",
    "    policy: PolicyBaseModel, steps: int = 20, debug: bool = False\n",
    "):\n",
    "    episode = Episode.new(id=\"inference\")\n",
    "    print(f\"start state: {episode.agent.current_state}\")\n",
    "    episode.inference_steps_by_policy(steps=steps, policy=policy, debug=debug)\n",
    "    print(f\"end state: {episode.agent.current_state}\")\n",
    "\n",
    "    fig = plt.figure(figsize=config.figure_size)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    episode.viz(ax=ax, color=get_color(0))\n",
    "    plt.show()\n",
    "\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4216ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = PolicyFactory.create(policy_mode=PolicyMode.LINEAR_MODEL, config=config).to(\n",
    "    config.device\n",
    ")\n",
    "\n",
    "episode = train_and_plot_policy(policy=policy, debug=True)\n",
    "episode.agent.action_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = PolicyFactory.create(policy_mode=PolicyMode.LINEAR_MODEL, config=config).to(\n",
    "    config.device\n",
    ")\n",
    "\n",
    "episode = inference_and_plot_policy(policy=policy, debug=True)\n",
    "episode.agent.action_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea75219",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_pos = torch.tensor([0, 80])\n",
    "fov = episode.fov(center_pos=center_pos)\n",
    "print(f\"fov: {fov.size()}\")\n",
    "print(f\"fov: {fov}\")\n",
    "\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "episode.world.viz_fov(center_pos=center_pos, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048d3db",
   "metadata": {},
   "source": [
    "# Train Policy Model\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d37715",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = PolicyFactory.create(policy_mode=PolicyMode.LINEAR_MODEL, config=config).to(\n",
    "    config.device\n",
    ")\n",
    "\n",
    "# GRPO\n",
    "# 1. Generate samples from the same starting state (same query)\n",
    "optimizer = torch.optim.AdamW(policy.parameters(), lr=1, weight_decay=0.01)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# for name, param in policy.brain[0].named_parameters():\n",
    "#     print(name, param)\n",
    "\n",
    "for iteration in range(10):\n",
    "    # each episode iteration is always starting from the same state\n",
    "    start_state = State.create_from(\n",
    "        config=config,\n",
    "        id=id,\n",
    "        x=(config.world_min_x + config.world_max_x) // 2,\n",
    "        y=(config.world_min_y + config.world_max_y) // 2,\n",
    "    )\n",
    "    target_state = State.create_from(\n",
    "        config=config,\n",
    "        id=\"earth\",\n",
    "        x=random.uniform(config.world_min_x, config.world_max_x),\n",
    "        y=random.uniform(config.world_min_y, config.world_max_y),\n",
    "    )\n",
    "\n",
    "    episodes = []\n",
    "    for episode_idx in range(config.episodes_per_iteration):\n",
    "        episode = Episode.create_from_state(\n",
    "            start_state=start_state, target_state=target_state\n",
    "        )\n",
    "        episode.train(steps=config.episode_steps, policy=policy, debug=False)\n",
    "        episodes.append(episode)\n",
    "\n",
    "    # 2. Compute the Advantages\n",
    "    episodes_rewards = torch.tensor(\n",
    "        [episode.reward() for episode in episodes], device=config.device\n",
    "    )\n",
    "    # print(f\"episodes rewards: {episodes_rewards}\")\n",
    "\n",
    "    r_std, r_mean = torch.std_mean(episodes_rewards)\n",
    "    writer.add_scalar(\"r_std\", r_std, iteration)\n",
    "    writer.add_scalar(\"r_mean\", r_mean, iteration)\n",
    "    if r_std == 0.0:\n",
    "        # print(f\"invalid episode, r_std: {r_std}\")\n",
    "        continue\n",
    "\n",
    "    r_advantages = (episodes_rewards - r_mean) / r_std\n",
    "    # print(f\"r_std: {r_std}, r_mean: {r_mean}, r_advantages: {r_advantages}\")\n",
    "\n",
    "    # 3. Compute the KL-\n",
    "    # N/A\n",
    "\n",
    "    # 4. Compute weighted rewards\n",
    "    advantage_weighted_rewards = episodes_rewards * r_advantages\n",
    "    # print(f\"advantage_weighted_rewards: {advantage_weighted_rewards}\")\n",
    "\n",
    "    episode_log_probs = torch.concat(\n",
    "        [episode.log_reward_prob() for episode in episodes]\n",
    "    ).to(config.device)\n",
    "    # print(f\"episode_log_probs: {episode_log_probs}\")\n",
    "    writer.add_histogram(f\"episode_log_probs\", episode_log_probs, iteration)\n",
    "\n",
    "    episode_probs = torch.concat([episode.reward_prob() for episode in episodes])\n",
    "    # print(f\"episode_probs: {episode_probs}\")\n",
    "    writer.add_histogram(f\"episode_probs\", episode_probs, iteration)\n",
    "\n",
    "    episode_weighted_rewards = (\n",
    "        advantage_weighted_rewards * episode_log_probs\n",
    "    )  # episode_probs\n",
    "    # print(f\"episode_weighted_rewards: {episode_weighted_rewards}\")\n",
    "    writer.add_histogram(\n",
    "        f\"episode_weighted_rewards\", episode_weighted_rewards, iteration\n",
    "    )\n",
    "\n",
    "    mean_episode_weighted_rewards = torch.mean(episode_weighted_rewards)\n",
    "    # print(f\"mean_episode_weighted_rewards: {mean_episode_weighted_rewards}\")\n",
    "    writer.add_scalar(\n",
    "        \"mean_episode_weighted_rewards\", mean_episode_weighted_rewards, iteration\n",
    "    )\n",
    "\n",
    "    # Debug\n",
    "    # def _print_grad(grad):\n",
    "    #     return\n",
    "    #     print(\"Gradient:\", grad)\n",
    "\n",
    "    # for name, param in policy.brain[0].named_parameters():\n",
    "    #     # print(name, param)\n",
    "    #     param.register_hook(_print_grad)\n",
    "\n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "    mean_episode_weighted_rewards.backward()\n",
    "    # for name, param in policy.brain[0].named_parameters():\n",
    "    #     print(name, param)\n",
    "\n",
    "    # Adjust learning weights\n",
    "    optimizer.step()\n",
    "\n",
    "    for name, param in policy.brain.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(f\"{name}.grad\", param.grad, iteration)\n",
    "\n",
    "    # for name, param in policy.brain[0].named_parameters():\n",
    "    #     print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes[0].log_reward_prob()\n",
    "lrps = [episode.log_reward_prob() for episode in episodes]\n",
    "torch.tensor(lrps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = inference_and_plot_policy(policy=policy, steps=100, debug=False)\n",
    "# episode.agent.action_history, episode.reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696436d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76311447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
